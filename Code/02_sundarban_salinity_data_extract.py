# -*- coding: utf-8 -*-
"""02_Sundarban_salinity_data_extract.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10OwRfUdmeSmOSK4RvS5K63yZEguCswYj

**Importing Necessary Libraries**: The script begins by importing necessary libraries:

1) ee: The Google Earth Engine library is imported to enable interactions with Earth Engine servers, which is crucial for accessing and processing large datasets of geospatial information.

2) pandas as pd: The pandas library, aliased as pd, is imported to facilitate data manipulation and analysis. This library provides data structures like dataframes and series along with the essential functionality required for cleaning, aggregating, transforming, visualizing, and more

3) geopandas as gpd: Geopandas, aliased as gpd, is imported to make working with geospatial data in python easier. It extends the datatypes used by pandas to include geometric types and performs geometric operations.

4)  The shapely.geometry module is imported for the manipulation and analysis of planar geometric objects. It provides a collection of geometric objects, and the methods and functions which can operate on these objects.

5) The logging module is imported to enable logging of messages in a wide variety of ways. This can be helpful for tracking the flow of the program and debugging.
"""

import ee
import pandas as pd
import geopandas as gpd
import logging
from shapely.geometry import Point

"""**Authentication and Initialization** The code authenticates and initializes the Earth Engine using ee.Authenticate() and ee.Initialize() respectively."""

ee.Authenticate()

ee.Initialize()

"""**Function 1: extract_data**
This function is tailored for data extraction from the Google Earth Engine, utilizing the specified parameters. This function is tailored to extract data from all bands of the dataset.

If no dataset is specified, it defaults to the 'HYCOM/sea_temp_salinity' dataset.
"""

def extract_data(start_date, end_date, dataset='HYCOM/sea_temp_salinity', region=None, scale=27830):
    try:
        collection = (ee.ImageCollection(dataset)
                      .filterDate(ee.Date(start_date), ee.Date(end_date))
                      .filterBounds(region))
        return collection
    except Exception as e:
        logging.exception(f"An error occurred during data extraction: {e}")
        return None

def process_data_to_dataframe(collection, start_date, end_date, temporal_resolution=16, region=None, scale=27830):
    data_points = []

    try:
        if collection is None:
            raise ValueError("No data available to process.")

        dates = pd.date_range(start=start_date, end=end_date, freq=f'{temporal_resolution}D')

        for single_date in dates:
            end_date = single_date + pd.Timedelta(days=temporal_resolution)
            filtered_collection = collection.filterDate(ee.Date(single_date.strftime("%Y-%m-%d")), ee.Date(end_date.strftime("%Y-%m-%d")))
            image = filtered_collection.mean()  # Taking the mean composite for the period

            reduction = image.reduceRegion(
              reducer=ee.Reducer.mean(),
              geometry=region,
              scale=scale,
              maxPixels=1e13
            )

            data = reduction.getInfo()
            data['year'] = single_date.year
            data['month'] = single_date.month
            data['latitude'] = region.centroid().coordinates().get(0).getInfo()
            data['longitude'] = region.centroid().coordinates().get(1).getInfo()

            data_points.append(data)

        df = pd.DataFrame(data_points)
        return df

    except Exception as e:
        logging.exception(f"An error occurred during data processing: {e}")
        return pd.DataFrame()

"""**Function 2: main**

The main function orchestrates the extraction, processing, and saving of sea temperature and salinity data.

1) A time range for data extraction is defined using the start and end dates.

2) The region of interest, Sundarbans Mangroves, is defined using a rectangular geometry.

3) Calls the extract_data function to extract data for the specified time range, dataset, region, and scale.

4) Calls the process_data_to_dataframe function to process the extracted data into a DataFrame. It specifies a temporal resolution of 16 days, along with the region and scale.

5) Outputs the DataFrame to a CSV file at the specified output path.

This block ensures that the main function is called when the script is run, initiating the data extraction, processing, and output sequence.
"""

def main(output_path='/content/drive/MyDrive/Processed_data/sea_temp_salinity_data.csv'):
    # Define the time range
    start_date = '2000-02-18'
    end_date = '2020-07-09'

    # Define the region of interest: Sundarbans Mangroves
    sundarbans = ee.Geometry.Rectangle([88.0, 21.5, 90.0, 22.5])

    # Step 1: Data Extraction
    collection = extract_data(start_date, end_date, dataset='HYCOM/sea_temp_salinity', region=sundarbans, scale = 8905.6)

    # Step 2: Data Processing
    df = process_data_to_dataframe(collection, start_date, end_date, temporal_resolution=16, region=sundarbans, scale = 8905.6)  # Assuming yearly interval

    # Output the DataFrame to a CSV file
    df.to_csv(output_path, index=False)

if __name__ == '__main__':
    main()