{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Importing Necessary Libraries**\n",
        "The script begins by importing necessary libraries:\n",
        "\n",
        "1) ee: Google Earth Engine library for interacting with Earth Engine servers.\n",
        "\n",
        "2) pandas as pd: A library for data manipulation and analysis.\n",
        "\n",
        "3) geopandas as gpd: An open-source project to make working with geospatial data in python easier.\n",
        "\n",
        "4) shapely.geometry: For manipulation and analysis of planar geometric objects.\n",
        "\n",
        "5) datetime: For working with dates as date objects."
      ],
      "metadata": {
        "id": "I3OQSQalU1io"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbHEA7Nbt4oA"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "from shapely.geometry import Point, Polygon\n",
        "from datetime import datetime\n",
        "import logging"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Authentication and Initialization**\n",
        "The code authenticates and initializes the Earth Engine using ee.Authenticate() and ee.Initialize() respectively."
      ],
      "metadata": {
        "id": "PWK3aJn6VTli"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "ee.Authenticate()\n",
        "\n",
        "ee.Initialize()"
      ],
      "metadata": {
        "id": "5QfEeNSTuUIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function 1: extract_data**\n",
        "This function is designed to extract data from Google Earth Engine based on the given parameters.\n",
        "\n",
        "1) If no region is provided, it defaults to a specified region (the Sundarbans).\n",
        "\n",
        "2) It creates an ImageCollection filtered by date and region, and selects a specific band (default is NDVI - Normalized Difference Vegetation Index)."
      ],
      "metadata": {
        "id": "D13TcJVbVb7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def extract_data(start_date, end_date, band='NDVI', dataset='MODIS/006/MOD13A2', region=None, scale=1000):\n",
        "    \"\"\"Extract data from Google Earth Engine.\"\"\"\n",
        "    try:\n",
        "        # Default to the Sundarbans if no region is provided\n",
        "        if region is None:\n",
        "            region = ee.Geometry.Rectangle([88.0, 21.5, 90.0, 22.5]).centroid()\n",
        "\n",
        "        collection = (ee.ImageCollection(dataset)\n",
        "                      .filterDate(ee.Date(start_date), ee.Date(end_date))\n",
        "                      .filterBounds(region)\n",
        "                      .select(band))\n",
        "        return collection\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred during data extraction: {e}\")\n",
        "        return None\n",
        "\n"
      ],
      "metadata": {
        "id": "QGmxSC_ciSYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function 2: process_data_to_dataframe**\n",
        "\n",
        "This function processes the Earth Engine data collection into a Pandas dataframe.\n",
        "\n",
        "1) If no data collection is provided, it raises a ValueError.\n",
        "\n",
        "2) If no region is specified, it defaults to the Sundarbans.\n",
        "\n",
        "3) It iterates over a range of dates, filters the collection for each date range, and computes the mean composite for each period.\n",
        "\n",
        "4) It reduces the region to a dictionary of means for the specified band, and constructs a dataframe from these data points."
      ],
      "metadata": {
        "id": "ejbZxpWnV4_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_to_dataframe(collection, start_date, end_date, band='NDVI', temporal_resolution=16, region=None, scale=1000):\n",
        "    \"\"\"Process the Earth Engine data collection into a Pandas dataframe.\"\"\"\n",
        "    data_points = []\n",
        "\n",
        "    try:\n",
        "        if collection is None:\n",
        "            raise ValueError(\"No data available to process.\")\n",
        "\n",
        "        # Default to the Sundarbans if no region is provided\n",
        "        if region is None:\n",
        "            region = ee.Geometry.Rectangle([88.0, 21.5, 90.0, 22.5]).centroid()\n",
        "\n",
        "        # Create a list of dates to iterate over\n",
        "        dates = pd.date_range(start=start_date, end=end_date, freq=f'{temporal_resolution}D')\n",
        "\n",
        "        for single_date in dates:\n",
        "            end_date = single_date + pd.Timedelta(days=temporal_resolution)\n",
        "            filtered_collection = collection.filterDate(ee.Date(single_date.strftime(\"%Y-%m-%d\")), ee.Date(end_date.strftime(\"%Y-%m-%d\")))\n",
        "            image = filtered_collection.mean()  # Taking the mean composite for the period\n",
        "\n",
        "            # This function will reduce region to a dictionary of means in the region set by the geometry\n",
        "            reduction = image.reduceRegion(\n",
        "              reducer=ee.Reducer.mean(),\n",
        "              geometry=region,\n",
        "              scale=scale,\n",
        "              maxPixels=1e13\n",
        "            )\n",
        "\n",
        "            data = reduction.getInfo()\n",
        "\n",
        "            # Check if the band is in the data\n",
        "            if band in data:\n",
        "                value = data[band]\n",
        "            else:\n",
        "                value = 'NA'  # If not, set a default value\n",
        "                logging.warning(f\"Data for {band} not available on {single_date.strftime('%Y-%m-%d')}\")\n",
        "\n",
        "            data_points.append({\n",
        "                'year': single_date.year,\n",
        "                'month': single_date.month,\n",
        "                band.lower(): value,\n",
        "                'latitude': region.coordinates().get(1).getInfo(),\n",
        "                'longitude': region.coordinates().get(0).getInfo(),\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(data_points)\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.error(f\"An error occurred during data processing: {e}\")\n",
        "        return pd.DataFrame()\n"
      ],
      "metadata": {
        "id": "V-qtUFM0V14_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function 3: main**\n",
        "\n",
        "The main function orchestrates the extraction and processing of data.\n",
        "\n",
        "1) It defines a time range for data extraction.\n",
        "\n",
        "2) It calls extract_data to extract data, and process_data_to_dataframe to process the extracted data from the MODIS/006/MOD13A2 into a dataframe.\n",
        "\n",
        "3) It then writes the dataframe to a CSV file at the specified output_path.\n",
        "\n",
        "This block ensures that the main function is called when the script is run."
      ],
      "metadata": {
        "id": "BJZMGjofWUNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(output_path='/content/drive/MyDrive/Processed_data/sundarban_ndvi.csv'):\n",
        "    # Define the time range\n",
        "    start_date = '2000-02-18'\n",
        "    end_date = '2020-07-09'\n",
        "\n",
        "    # Step 1: Data Extraction\n",
        "    collection = extract_data(start_date, end_date, band='NDVI')\n",
        "\n",
        "    # Step 2: Data Processing\n",
        "    df = process_data_to_dataframe(collection, start_date, end_date, band='NDVI')\n",
        "\n",
        "    # Output the DataFrame to a CSV file\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "TuEBy5R2D_jL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b7dc4a2-cf14-42f1-f3cc-d903aadcd52b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:root:Data for NDVI not available on 2020-07-02\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function 4: main**\n",
        "\n",
        "The main function serves as the entry point to the script, coordinating the data extraction, processing, and saving the air temperature data to a CSV file. Time Range Definition:\n",
        "\n",
        "1) The time range for data extraction is defined by specifying start_date and end_date.\n",
        "\n",
        "2) The extract_data function is called with the specified time range, band, and dataset to extract the data from the ECMWF/ERA5/DAILY dataset for the mean 2-meter air temperature.\n",
        "\n",
        "3) The process_data_to_dataframe function is called to process the extracted data into a dataframe. The temporal resolution and scale are specified as arguments.\n",
        "\n",
        "4) The dataframe is then written to a CSV file at the specified output_path.\n",
        "\n",
        "This block ensures that the main function is called when the script is run.\n",
        "\n"
      ],
      "metadata": {
        "id": "up6C4_3mTsJQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(output_path='/content/drive/MyDrive/Processed_data/temperature_data.csv'):\n",
        "    # Define the time range\n",
        "    start_date = '2000-02-18'\n",
        "    end_date = '2020-07-09'\n",
        "\n",
        "    # Step 1: Data Extraction\n",
        "    collection = extract_data(start_date, end_date, band='mean_2m_air_temperature', dataset='ECMWF/ERA5/DAILY')\n",
        "\n",
        "    # Step 2: Data Processing\n",
        "    df = process_data_to_dataframe(collection, start_date, end_date, band='mean_2m_air_temperature', temporal_resolution=16,\n",
        "                                   scale=27830)\n",
        "\n",
        "    # Output the DataFrame to a CSV file\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "TBM6BqOurJN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function 5: main**\n",
        "\n",
        "The main function orchestrates the steps of data extraction, processing, and exporting in relation to precipitation data.\n",
        "\n",
        "1) A time range for data extraction is defined by specifying the start_date and end_date.\n",
        "\n",
        "2) The extract_data function is invoked to extract data concerning total precipitation from the ECMWF/ERA5/DAILY dataset within the defined time range.\n",
        "\n",
        "3) The process_data_to_dataframe function is utilized to process the extracted data into a DataFrame, with specific arguments for the band, temporal resolution, and scale.\n",
        "\n",
        "4) The DataFrame is then outputted to a CSV file at the specified output_path.\n",
        "\n",
        "This block ensures that the main function is executed when the script is run."
      ],
      "metadata": {
        "id": "CW3FcligVZmR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(output_path='/content/drive/MyDrive/Processed_data/precipitation_data.csv'):\n",
        "    # Define the time range\n",
        "    start_date = '2000-02-18'\n",
        "    end_date = '2020-07-09'\n",
        "\n",
        "    # Step 1: Data Extraction\n",
        "    collection = extract_data(start_date, end_date, band='total_precipitation', dataset='ECMWF/ERA5/DAILY')\n",
        "\n",
        "    # Step 2: Data Processing\n",
        "    df = process_data_to_dataframe(collection, start_date, end_date, band='total_precipitation', temporal_resolution=16,\n",
        "                                   scale = 27830)\n",
        "\n",
        "    # Output the DataFrame to a CSV file\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "CYUTwfLuxtR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function 5: main**\n",
        "\n",
        "The main function orchestrates the steps of data extraction, processing, and exporting in relation to surface elevation data.\n",
        "\n",
        "1) A time range for data extraction is defined by specifying the start_date and end_date.\n",
        "\n",
        "2) The extract_data function is invoked to extract data concerning total precipitation from the HYCOM/sea_surface_elevation dataset within the defined time range.\n",
        "\n",
        "3) The process_data_to_dataframe function is utilized to process the extracted data into a DataFrame, with specific arguments for the band, temporal resolution, and scale.\n",
        "\n",
        "4) The DataFrame is then outputted to a CSV file at the specified output_path.\n",
        "\n",
        "This block ensures that the main function is executed when the script is run."
      ],
      "metadata": {
        "id": "6YZv1weMWn_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main(output_path='/content/drive/MyDrive/Processed_data/sea_surface_anomaly_data.csv'):\n",
        "    # Define the time range\n",
        "    start_date = '2000-02-18'\n",
        "    end_date = '2020-07-09'\n",
        "\n",
        "    # Step 1: Data Extraction\n",
        "    collection = extract_data(start_date, end_date, band='surface_elevation', dataset='HYCOM/sea_surface_elevation')\n",
        "\n",
        "    # Step 2: Data Processing\n",
        "    df = process_data_to_dataframe(collection, start_date, end_date, band='surface_elevation', temporal_resolution=16,\n",
        "                                   scale = 8905.6)\n",
        "\n",
        "    # Output the DataFrame to a CSV file\n",
        "    df.to_csv(output_path, index=False)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "pHvMbEkwEEqi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}